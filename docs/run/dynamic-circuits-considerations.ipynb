{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hardware considerations and limitations for classical feedforward and control flow\n",
    "\n",
    "[Classical feedforward and control flow](/build/classical-feedforward-and-control-flow) shows how to use Qiskit to build circuits that involve classical feedforward and control flow, also known as dynamic circuits. When actually running such circuits on quantum hardware, there are several considerations to be aware of.\n",
    "\n",
    "## Does not work with primitives\n",
    "\n",
    "Currently, circuits with classical control flow cannot be executed with the Qiskit Runtime primitives. The only way to run them on hardware is to use the `backend.run` function, where `backend` is an IBMBackend object.\n",
    "\n",
    "## Must pass `dynamic=True` to `backend.run`\n",
    "\n",
    "When running a circuit with classical control flow using `backend.run`, one must specfy the `dynamic=True` flag. For example:\n",
    "\n",
    "```python\n",
    "job = backend.run(circuit, dynamic=True)\n",
    "```\n",
    "\n",
    "## Memory limits and latency in control hardware\n",
    "\n",
    "![Diagram showing control hardware architecture](/images/run/rta-architecture.png)\n",
    "\n",
    "Running circuits on quantum processors involves not only the qubits themselves, but also a system of classical electronics and computers to generate and receive waveforms and orchestrate the control logic. When a job is submitted to the IBM Quantum service, it is processed into multiple classical programs that must be distributed between two kinds of units: central controllers and qubit controllers (see diagram above). A job may fail if it exceeds certain limitations of these controllers. There are two kinds of limitations to be aware of:\n",
    "\n",
    "- **Limited working memory**. This primarily affects the central controllers, and jobs will fail if they cause this memory limit to be exceeded.\n",
    "- **Latency caused by classical computation**. Running circuits that use classical feedforward and control flow involves performing classical computation during the course of the circuit execution. Due to the limited coherence time of qubits, there is a limited time budget for performing these computations. A job may fail at compile time if the compilation detects that the classical computation overhead is too large.\n",
    "\n",
    "The memory requirements and classical latencies of a job are affected by the following factors:\n",
    "\n",
    "- **Number of circuits**. When multiple circuits are submitted in a single job, they become concatenated into a single large circuit, with qubit initialization operations between them. Qubit initialization is implemented as a conditional reset on all qubits used in the large circuit.\n",
    "  - Central controller: Memory usage scales proportionally with the number of circuits.\n",
    "- **Amount of control flow**.\n",
    "  - Central controller: Memory usage scales proportionally with the number of control flow decisions.\n",
    "  - Qubit controller: A control flow construct with too many or too large logic branches may not be realizable.\n",
    "- **Resets**.\n",
    "  - Central controller: Memory usage scales proportionally with the number of resets.\n",
    "- **Measurements**.\n",
    "  - Central controller: Memory usage scales proportionally with the number of measurements used by the central controller for control flow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the rest of this section we provide some example code that you can use to probe these limits yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit_ibm_provider import IBMProvider\n",
    "\n",
    "hub = \"ibm-q-internal\"\n",
    "group = \"deployed\"\n",
    "project = \"default\"\n",
    "\n",
    "provider = IBMProvider(instance=f\"{hub}/{group}/{project}\")\n",
    "\n",
    "backend_name = \"ibmq_jakarta\"\n",
    "backend = provider.get_backend(backend_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test `num_qubits` x `num_circuits`\n",
    "\n",
    "Here, we run a sweep to determine job limits as a function of the number of qubits and the number of circuits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Number of qubits to sweep over\n",
    "num_qubit_steps = 5\n",
    "# Number of circuits to sweep over\n",
    "num_circuit_steps = 5\n",
    "\n",
    "max_circuits = 300\n",
    "num_qubits = backend.num_qubits\n",
    "shots = 100\n",
    "\n",
    "save = True\n",
    "\n",
    "qubit_steps = np.concatenate(\n",
    "    [\n",
    "        [1],\n",
    "        np.arange(0, num_qubits, step=int(num_qubits / num_qubit_steps))[\n",
    "            1 : num_qubit_steps - 1\n",
    "        ],\n",
    "        [num_qubits],\n",
    "    ]\n",
    ")\n",
    "circuit_steps = np.concatenate(\n",
    "    [\n",
    "        [1],\n",
    "        np.arange(0, max_circuits, step=int(max_circuits / num_circuit_steps))[\n",
    "            1 : num_circuit_steps - 1\n",
    "        ],\n",
    "        [max_circuits],\n",
    "    ]\n",
    ")\n",
    "print(f\"Qubit steps: {qubit_steps}\")\n",
    "print(f\"Circuit steps: {circuit_steps}\")\n",
    "print(f\"Total number of experiments to be run: {num_qubit_steps*num_circuit_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import ClassicalRegister, QuantumCircuit, QuantumRegister, transpile\n",
    "\n",
    "\n",
    "def build_qubit_by_circuit_qcs(num_circuits, num_qubits, backend):\n",
    "    \"\"\"Build a list of transpiled circuits of n_circuits where each circuit trivially uses n_qubits\"\"\"\n",
    "\n",
    "    qr = QuantumRegister(num_qubits)\n",
    "    cr = ClassicalRegister(num_qubits)\n",
    "    qc = QuantumCircuit(qr, cr)\n",
    "    qc.x(qr)\n",
    "    qc.measure(qr, cr)\n",
    "\n",
    "    qc = transpile(qc, backend)\n",
    "\n",
    "    qcs = [qc.copy() for i in range(num_circuits)]\n",
    "\n",
    "    return qcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from qiskit_ibm_provider.job.exceptions import (\n",
    "    IBMJobFailureError,\n",
    "    IBMJobInvalidStateError,\n",
    ")\n",
    "\n",
    "col_names = [\n",
    "    \"job_id\",\n",
    "    \"time\",\n",
    "    \"num_circuits\",\n",
    "    \"num_qubits\",\n",
    "    \"num_conditionals\",\n",
    "    \"num_resets\",\n",
    "    \"success\",\n",
    "]\n",
    "circuit_qubit_df = pd.DataFrame(columns=col_names)\n",
    "circuit_qubit_path = Path(\n",
    "    f\"circuit_qubit_sweep_{datetime.now().strftime('%Y_%m_%d_%H_%M_%S')}.df\"\n",
    ").resolve()\n",
    "\n",
    "# Run\n",
    "circuit_qubit_jobs = {}\n",
    "for num_circuits in circuit_steps:\n",
    "    for num_qubits in qubit_steps:\n",
    "        qcs = build_qubit_by_circuit_qcs(num_circuits, num_qubits, backend)\n",
    "        job = backend.run(qcs, dynamic=True, shots=shots)\n",
    "        print(\n",
    "            f\"Running - num_circuits: {num_circuits}, num_qubits: {num_qubits}, job id: {job.job_id()}\"\n",
    "        )\n",
    "        circuit_qubit_jobs[(num_circuits, num_qubits)] = job\n",
    "\n",
    "# Fetch\n",
    "for num_circuits in circuit_steps:\n",
    "    for num_qubits in qubit_steps:\n",
    "        job = circuit_qubit_jobs[(num_circuits, num_qubits)]\n",
    "\n",
    "        success = 0\n",
    "        try:\n",
    "            print(\n",
    "                f\"Awaiting result - num_circuits: {num_circuits}, num_qubits: {num_qubits}, job id: {job.job_id()}\"\n",
    "            )\n",
    "            result = job.result()\n",
    "            success = 1\n",
    "\n",
    "        except IBMJobFailureError:\n",
    "            success = -1\n",
    "        except IBMJobInvalidStateError:\n",
    "            success = -1\n",
    "\n",
    "        circuit_qubit_df.loc[len(circuit_qubit_df)] = {\n",
    "            \"job_id\": job.job_id(),\n",
    "            \"time\": datetime.now(),\n",
    "            \"num_circuits\": num_circuits,\n",
    "            \"num_qubits\": num_qubits,\n",
    "            \"num_conditionals\": 0,\n",
    "            \"num_resets\": 0,\n",
    "            \"success\": success,\n",
    "        }\n",
    "\n",
    "if save:\n",
    "    print(f\"Saving data to {circuit_qubit_path}\")\n",
    "    circuit_qubit_df.to_csv(circuit_qubit_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit_qubit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 12)\n",
    "\n",
    "cmap = LinearSegmentedColormap.from_list(\"rg\", [\"r\", \"w\", \"g\"], N=256)\n",
    "linewidths = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes()\n",
    "\n",
    "heat_data = circuit_qubit_df.drop_duplicates(\n",
    "    subset=[\"num_qubits\", \"num_circuits\"], keep=\"first\"\n",
    ").pivot(columns=\"num_circuits\", index=\"num_qubits\", values=\"success\")\n",
    "sns.heatmap(heat_data, cmap=cmap, ax=ax, linewidths=0.1, vmin=-1, vmax=1)\n",
    "ax.set_title(\"Comparing execution success as a function of num_qubits & num_circuits\")\n",
    "ax.invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test `num_conditional` x `num_circuits`\n",
    "\n",
    "Here, we run a sweep to determine job limits as a function of the number of conditionals and the number of circuits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Number of conditionals to sweep over\n",
    "num_conditional_steps = 5\n",
    "# Number of circuits to sweep over\n",
    "num_circuit_steps = 4\n",
    "\n",
    "max_conditionals = 500\n",
    "max_circuits_cond = 10\n",
    "\n",
    "# Add a 20us delay between measurements to ensure we don't overflow the buffer\n",
    "# and can stream results back to the device.\n",
    "cond_delay = 20e-6\n",
    "\n",
    "MAX_REGISTER_SIZE = 64  # Pending resolution of https://github.ibm.com/IBM-Q-Restricted-System/qic-rta-driver/issues/949\n",
    "circuit_cond_num_qubits = min(num_qubits, MAX_REGISTER_SIZE)\n",
    "\n",
    "save = True\n",
    "\n",
    "cond_steps = np.concatenate(\n",
    "    [\n",
    "        [1],\n",
    "        np.arange(\n",
    "            0, max_conditionals, step=int(max_conditionals / num_conditional_steps)\n",
    "        )[1 : num_conditional_steps - 1],\n",
    "        [max_conditionals],\n",
    "    ]\n",
    ")\n",
    "circuit_steps = np.concatenate(\n",
    "    [\n",
    "        [1],\n",
    "        np.arange(\n",
    "            0, max_circuits_cond, step=int(max_circuits_cond / num_circuit_steps)\n",
    "        )[1 : num_circuit_steps - 1],\n",
    "        [max_circuits_cond],\n",
    "    ]\n",
    ")\n",
    "print(f\"Conditional steps: {cond_steps}\")\n",
    "print(f\"Circuit steps: {circuit_steps}\")\n",
    "print(\n",
    "    f\"Number of qubits to measure/make a decision based on: {circuit_cond_num_qubits}\"\n",
    ")\n",
    "print(f\"Total number of experiments to be run: {len(cond_steps)*len(circuit_steps)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import ClassicalRegister, QuantumCircuit, QuantumRegister, transpile\n",
    "\n",
    "\n",
    "def build_cond_by_circuit_qcs(num_circuits, num_conds, num_qubits, backend):\n",
    "    \"\"\"Build a list of transpiled circuits of n_circuits where each circuit trivially uses n_conditionals\"\"\"\n",
    "\n",
    "    qr = QuantumRegister(num_qubits)\n",
    "    cr = ClassicalRegister(num_qubits)\n",
    "    qc = QuantumCircuit(qr, cr)\n",
    "    for i in range(num_conds):\n",
    "        qc.measure(qr, cr)\n",
    "        with qc.if_test((cr, 1)):\n",
    "            qc.x(qr)\n",
    "        qc.barrier(qr)\n",
    "        qc.delay(cond_delay, qr, unit=\"s\")\n",
    "\n",
    "    qc = transpile(qc, backend)\n",
    "\n",
    "    qcs = [qc.copy() for i in range(num_circuits)]\n",
    "\n",
    "    return qcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from qiskit_ibm_provider.job.exceptions import (\n",
    "    IBMJobFailureError,\n",
    "    IBMJobInvalidStateError,\n",
    ")\n",
    "\n",
    "col_names = [\n",
    "    \"job_id\",\n",
    "    \"time\",\n",
    "    \"num_circuits\",\n",
    "    \"num_qubits\",\n",
    "    \"num_conditionals\",\n",
    "    \"num_resets\",\n",
    "    \"success\",\n",
    "]\n",
    "circuit_cond_df = pd.DataFrame(columns=col_names)\n",
    "circuit_cond_path = Path(\n",
    "    f\"circuit_cond_sweep_{datetime.now().strftime('%Y_%m_%d_%H_%M_%S')}.df\"\n",
    ").resolve()\n",
    "\n",
    "# Run\n",
    "circuit_conds_jobs = {}\n",
    "for num_circuits in circuit_steps:\n",
    "    for num_conds in cond_steps:\n",
    "        qcs = build_cond_by_circuit_qcs(num_circuits, num_conds, num_qubits, backend)\n",
    "        job = backend.run(qcs, dynamic=True, shots=shots)\n",
    "        print(\n",
    "            f\"Running - num_circuits: {num_circuits}, num_conditionals: {num_conds}, job id: {job.job_id()}\"\n",
    "        )\n",
    "        circuit_conds_jobs[(num_circuits, num_conds)] = job\n",
    "\n",
    "# Fetch\n",
    "for num_circuits in circuit_steps:\n",
    "    for num_conds in cond_steps:\n",
    "        job = circuit_conds_jobs[(num_circuits, num_conds)]\n",
    "\n",
    "        success = 0\n",
    "        try:\n",
    "            print(\n",
    "                f\"Awaiting result - num_circuits: {num_circuits}, num_conditionals: {num_conds}, job id: {job.job_id()}\"\n",
    "            )\n",
    "            result = job.result()\n",
    "            success = 1\n",
    "\n",
    "        except IBMJobFailureError:\n",
    "            success = -1\n",
    "        except IBMJobInvalidStateError:\n",
    "            success = -1\n",
    "\n",
    "        circuit_cond_df.loc[len(circuit_cond_df)] = {\n",
    "            \"job_id\": job.job_id(),\n",
    "            \"time\": datetime.now(),\n",
    "            \"num_circuits\": num_circuits,\n",
    "            \"num_qubits\": 1,\n",
    "            \"num_conditionals\": num_conds,\n",
    "            \"num_resets\": 0,\n",
    "            \"success\": success,\n",
    "        }\n",
    "\n",
    "if save:\n",
    "    print(f\"Saving data to {circuit_cond_path}\")\n",
    "    circuit_cond_df.to_csv(circuit_cond_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit_cond_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes()\n",
    "heat_data = circuit_cond_df.drop_duplicates(\n",
    "    subset=[\"num_conditionals\", \"num_circuits\"], keep=\"first\"\n",
    ").pivot(index=\"num_circuits\", columns=\"num_conditionals\", values=\"success\")\n",
    "sns.heatmap(heat_data, cmap=cmap, ax=ax, linewidths=0.1, vmin=-1, vmax=1)\n",
    "ax.set_title(\n",
    "    \"Comparing execution success as a function of num_conditionals & num_circuits\"\n",
    ")\n",
    "ax.invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test `num_resets` x `num_qubits`\n",
    "\n",
    "Here, we run a sweep to determine job limits as a function of the number of resets and the number of qubits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Number of resets to sweep over\n",
    "num_reset_steps = 8\n",
    "# Number of circuits to sweep over\n",
    "num_qubit_steps = 3\n",
    "\n",
    "max_resets = 1000\n",
    "max_qubits = backend.num_qubits\n",
    "\n",
    "# No delay is required as\n",
    "# reset measurement results are not\n",
    "# transmitted back to the host controller\n",
    "# which is where the bottle-neck with too many\n",
    "# MCM occurs.\n",
    "# cond_delay = 20e-6\n",
    "\n",
    "\n",
    "save = True\n",
    "\n",
    "reset_steps = np.concatenate(\n",
    "    [\n",
    "        [1],\n",
    "        np.arange(0, max_resets, step=int(max_resets / num_reset_steps))[\n",
    "            1 : num_reset_steps - 1\n",
    "        ],\n",
    "        [max_resets],\n",
    "    ]\n",
    ")\n",
    "qubit_steps = np.concatenate(\n",
    "    [\n",
    "        [1],\n",
    "        np.arange(0, max_qubits, step=int(max_qubits / num_qubit_steps))[\n",
    "            1 : num_qubit_steps - 1\n",
    "        ],\n",
    "        [max_qubits],\n",
    "    ]\n",
    ")\n",
    "print(f\"Reset steps: {cond_steps}\")\n",
    "print(f\"Qubit steps: {circuit_steps}\")\n",
    "print(f\"Total number of experiments to be run: {len(reset_steps)*len(qubit_steps)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import ClassicalRegister, QuantumCircuit, QuantumRegister, transpile\n",
    "\n",
    "\n",
    "def build_reset_by_qubits_qc(num_resets, num_qubits, backend):\n",
    "    \"\"\"Build a single circuit with `num_resets` and `num_qubits` and a final measurement\"\"\"\n",
    "\n",
    "    qr = QuantumRegister(num_qubits)\n",
    "    cr = ClassicalRegister(num_qubits)\n",
    "    qc = QuantumCircuit(qr, cr)\n",
    "    for i in range(num_resets):\n",
    "        qc.reset(qr)\n",
    "        qc.barrier(qr)\n",
    "    qc.measure_all()\n",
    "\n",
    "    qc = transpile(qc, backend)\n",
    "\n",
    "    return qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from qiskit_ibm_provider.job.exceptions import IBMJobFailureError\n",
    "\n",
    "col_names = [\n",
    "    \"job_id\",\n",
    "    \"time\",\n",
    "    \"num_circuits\",\n",
    "    \"num_qubits\",\n",
    "    \"num_conditionals\",\n",
    "    \"num_resets\",\n",
    "    \"success\",\n",
    "]\n",
    "qubit_reset_df = pd.DataFrame(columns=col_names)\n",
    "qubit_reset_path = Path(\n",
    "    f\"qubit_reset_sweep_{datetime.now().strftime('%Y_%m_%d_%H_%M_%S')}.df\"\n",
    ").resolve()\n",
    "\n",
    "# Run\n",
    "qubit_resets_jobs = {}\n",
    "for num_qubits in qubit_steps:\n",
    "    for num_resets in reset_steps:\n",
    "        qc = build_reset_by_qubits_qc(num_resets, num_qubits, backend)\n",
    "        # Disable init_qubits as this would insert additional resets to initialize\n",
    "        # our qubits which would impact the data we gather.\n",
    "        job = backend.run(qc, dynamic=True, shots=shots, init_qubits=False)\n",
    "        print(\n",
    "            f\"Running - num_qubits: {num_qubits}, num_conditionals: {num_resets}, job id: {job.job_id()}\"\n",
    "        )\n",
    "        qubit_resets_jobs[(num_qubits, num_resets)] = job\n",
    "\n",
    "# Fetch\n",
    "for num_qubits in qubit_steps:\n",
    "    for num_resets in reset_steps:\n",
    "        job = qubit_resets_jobs[(num_qubits, num_resets)]\n",
    "\n",
    "        success = 0\n",
    "        try:\n",
    "            print(\n",
    "                f\"Awaiting result - num_qubits: {num_qubits}, num_resets: {num_resets}, job id: {job.job_id()}\"\n",
    "            )\n",
    "            result = job.result()\n",
    "            success = 1\n",
    "\n",
    "        except IBMJobFailureError:\n",
    "            success = -1\n",
    "        except IBMJobInvalidStateError:\n",
    "            success = -1\n",
    "\n",
    "        qubit_reset_df.loc[len(qubit_reset_df)] = {\n",
    "            \"job_id\": job.job_id(),\n",
    "            \"time\": datetime.now(),\n",
    "            \"num_circuits\": 1,\n",
    "            \"num_qubits\": num_qubits,\n",
    "            \"num_conditionals\": 0,\n",
    "            \"num_resets\": num_resets,\n",
    "            \"success\": success,\n",
    "        }\n",
    "\n",
    "if save:\n",
    "    print(f\"Saving data to {qubit_reset_path}\")\n",
    "    qubit_reset_df.to_csv(qubit_reset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qubit_reset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes()\n",
    "heat_data = qubit_reset_df.drop_duplicates(\n",
    "    subset=[\"num_qubits\", \"num_resets\"], keep=\"first\"\n",
    ").pivot(index=\"num_resets\", columns=\"num_qubits\", values=\"success\")\n",
    "sns.heatmap(heat_data, cmap=cmap, ax=ax, linewidths=0.1, vmin=-1, vmax=1)\n",
    "ax.set_title(\"Comparing execution success as a function of num_qubits & num_resets\")\n",
    "ax.invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the limits of the switch statement as a function of  `num_cases` x `num_operations`\n",
    "\n",
    "Here, we run a sweep to determine job limits as a function of the number of switch statement cases and the number of gates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Number of switch cases to sweep over\n",
    "num_case_steps = 6\n",
    "# Number of gates per-qubit to sweep over\n",
    "num_gate_steps = 4\n",
    "\n",
    "max_cases = 2**11 - 1  # Include default case\n",
    "max_gates = 2**8\n",
    "\n",
    "shots = 100\n",
    "\n",
    "switch_case_num_qubits = backend.num_qubits\n",
    "\n",
    "save = True\n",
    "\n",
    "case_steps = np.concatenate(\n",
    "    [\n",
    "        [1],\n",
    "        np.arange(0, max_cases, step=int(max_cases / num_case_steps))[\n",
    "            1 : num_case_steps - 1\n",
    "        ],\n",
    "        [max_cases],\n",
    "    ]\n",
    ")\n",
    "gate_steps = np.concatenate(\n",
    "    [\n",
    "        [1],\n",
    "        np.arange(0, max_gates, step=int(max_gates / num_gate_steps))[\n",
    "            1 : num_gate_steps - 1\n",
    "        ],\n",
    "        [max_gates],\n",
    "    ]\n",
    ")\n",
    "print(f\"Switch case steps: {case_steps}\")\n",
    "print(f\"Gate count's per switch case steps: {gate_steps}\")\n",
    "print(f\"Total number of experiments to be run: {len(case_steps)*len(gate_steps)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import ClassicalRegister, QuantumCircuit, QuantumRegister, transpile\n",
    "\n",
    "\n",
    "def build_switch_cases_by_gates_qc(num_cases, num_gates, num_qubits, backend):\n",
    "    \"\"\"Build a list of transpiled circuits of n_circuits where each circuit trivially uses n_conditionals\"\"\"\n",
    "\n",
    "    n_measures = max(int(np.ceil(np.log2(num_cases))), 1)\n",
    "    qr = QuantumRegister(num_qubits)\n",
    "    cr = ClassicalRegister(n_measures)\n",
    "    cr_res = ClassicalRegister(num_qubits)\n",
    "    qc = QuantumCircuit(qr, cr, cr_res)\n",
    "\n",
    "    for i in range(n_measures):\n",
    "        if i % num_qubits == 0:\n",
    "            # Prepare measurement register randomly\n",
    "            qc.h(qr)\n",
    "            qc.barrier(qr)\n",
    "        qc.measure(i % num_qubits, cr[i])\n",
    "\n",
    "    qc.barrier(qr)\n",
    "\n",
    "    with qc.switch(cr) as case:\n",
    "        # metaprogram case loops\n",
    "        for case_idx in range(num_cases):\n",
    "            with case(case_idx):\n",
    "                # metaprogram gates within case\n",
    "                for num_gate in range(num_gates):\n",
    "                    qc.x(qr)\n",
    "                    qc.barrier(qr)\n",
    "        with case(case.DEFAULT):\n",
    "            pass\n",
    "\n",
    "    qc.barrier(qr)\n",
    "    qc.measure(qr, cr_res)\n",
    "\n",
    "    qc = transpile(qc, backend, optimization_level=0)\n",
    "\n",
    "    return qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from qiskit_ibm_provider.job.exceptions import (\n",
    "    IBMJobFailureError,\n",
    "    IBMJobInvalidStateError,\n",
    ")\n",
    "\n",
    "col_names = [\n",
    "    \"job_id\",\n",
    "    \"time\",\n",
    "    \"num_circuits\",\n",
    "    \"num_qubits\",\n",
    "    \"num_conditionals\",\n",
    "    \"num_resets\",\n",
    "    \"num_switches\",\n",
    "    \"num_cases\",\n",
    "    \"num_gates\",\n",
    "    \"success\",\n",
    "]\n",
    "case_gates_df = pd.DataFrame(columns=col_names)\n",
    "case_gates_path = Path(\n",
    "    f\"case_gates_sweep_{datetime.now().strftime('%Y_%m_%d_%H_%M_%S')}.df\"\n",
    ").resolve()\n",
    "\n",
    "# Run\n",
    "case_gates_jobs = {}\n",
    "for num_cases in case_steps:\n",
    "    for num_gates in gate_steps:\n",
    "        start = datetime.now()\n",
    "        qc = build_switch_cases_by_gates_qc(\n",
    "            num_cases, num_gates, switch_case_num_qubits, backend\n",
    "        )\n",
    "        build = datetime.now()\n",
    "        job = backend.run(qc, dynamic=True, shots=shots, init_qubits=False)\n",
    "        submit = datetime.now()\n",
    "        print(\n",
    "            f\"Running - num_cases: {num_cases}, num_gates: {num_gates}, job id: {job.job_id()}, build time: {(build-start).total_seconds()}, submit time: {(submit-build).total_seconds()}\"\n",
    "        )\n",
    "        case_gates_jobs[(num_cases, num_gates)] = job\n",
    "\n",
    "# Fetch\n",
    "for num_cases in case_steps:\n",
    "    for num_gates in gate_steps:\n",
    "        job = case_gates_jobs[(num_cases, num_gates)]\n",
    "\n",
    "        success = 0\n",
    "        try:\n",
    "            print(\n",
    "                f\"Awaiting result - num_cases: {num_cases}, num_gates: {num_gates}, job id: {job.job_id()}\"\n",
    "            )\n",
    "            result = job.result()\n",
    "            success = 1\n",
    "\n",
    "        except IBMJobFailureError:\n",
    "            success = -1\n",
    "        except IBMJobInvalidStateError:\n",
    "            success = -1\n",
    "\n",
    "        case_gates_df.loc[len(case_gates_df)] = {\n",
    "            \"job_id\": job.job_id(),\n",
    "            \"time\": datetime.now(),\n",
    "            \"num_circuits\": 1,\n",
    "            \"num_qubits\": 1,\n",
    "            \"num_conditionals\": 1,\n",
    "            \"num_resets\": 0,\n",
    "            \"num_switches\": 1,\n",
    "            \"num_cases\": num_cases,\n",
    "            \"num_gates\": num_gates,\n",
    "            \"success\": success,\n",
    "        }\n",
    "\n",
    "if save:\n",
    "    print(f\"Saving data to {case_gates_path}\")\n",
    "    case_gates_df.to_csv(case_gates_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch\n",
    "for num_cases in case_steps:\n",
    "    for num_gates in gate_steps:\n",
    "        job = case_gates_jobs[(num_cases, num_gates)]\n",
    "\n",
    "        success = 0\n",
    "        try:\n",
    "            print(\n",
    "                f\"Awaiting result - num_cases: {num_cases}, num_gates: {num_gates}, job id: {job.job_id()}\"\n",
    "            )\n",
    "            result = job.result()\n",
    "            success = 1\n",
    "\n",
    "        except IBMJobFailureError:\n",
    "            success = -1\n",
    "        except IBMJobInvalidStateError:\n",
    "            success = -1\n",
    "\n",
    "        case_gates_df.loc[len(case_gates_df)] = {\n",
    "            \"job_id\": job.job_id(),\n",
    "            \"time\": datetime.now(),\n",
    "            \"num_circuits\": 1,\n",
    "            \"num_qubits\": 1,\n",
    "            \"num_conditionals\": 1,\n",
    "            \"num_resets\": 0,\n",
    "            \"num_switches\": 1,\n",
    "            \"num_cases\": num_cases,\n",
    "            \"num_gates\": num_gates,\n",
    "            \"success\": success,\n",
    "        }\n",
    "\n",
    "if save:\n",
    "    print(f\"Saving data to {case_gates_path}\")\n",
    "    case_gates_df.to_csv(case_gates_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_gates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes()\n",
    "heat_data = case_gates_df.drop_duplicates(\n",
    "    subset=[\"num_cases\", \"num_gates\"], keep=\"first\"\n",
    ").pivot(index=\"num_cases\", columns=\"num_gates\", values=\"success\")\n",
    "sns.heatmap(heat_data, cmap=cmap, ax=ax, linewidths=0.1, vmin=-1, vmax=1)\n",
    "ax.set_title(\n",
    "    \"Comparing execution success as a function of the number of num_switch_cases & num_gates\"\n",
    ")\n",
    "ax.invert_yaxis()"
   ]
  }
 ],
 "metadata": {
  "description": "Article on hardware considerations and limitations for classical feedforward and control flow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "title": "Hardware considerations and limitations for classical feedforward and control flow"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
